{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNHPUN5Uc0wr+wKEojbzDSk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f0e16d7eb9c64a89a7336628c06404aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca7192e1109f465699738cdd49fe9d66","IPY_MODEL_c19f8eb544e44fdab356ac99af9534a4","IPY_MODEL_09a83dba494a412d97c9c8d55c37a733"],"layout":"IPY_MODEL_0bd7414d885841f9997e96acb7bcddad"}},"ca7192e1109f465699738cdd49fe9d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b3865999e044ec9b48ac00150137087","placeholder":"​","style":"IPY_MODEL_5e80785c413d4fd38d29b80bba1f77d5","value":"RGBSeg2IR.zip: 100%"}},"c19f8eb544e44fdab356ac99af9534a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41ef578d5ff24a69ac7801fb2952930e","max":548538587,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf5bd69dab054f3ebffb2dfe4fbda417","value":548538587}},"09a83dba494a412d97c9c8d55c37a733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af40339b6c54d7b809bf74761a1324c","placeholder":"​","style":"IPY_MODEL_e12175b4a7984be79246200a0c11f11c","value":" 549M/549M [00:01&lt;00:00, 443MB/s]"}},"0bd7414d885841f9997e96acb7bcddad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b3865999e044ec9b48ac00150137087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e80785c413d4fd38d29b80bba1f77d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41ef578d5ff24a69ac7801fb2952930e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf5bd69dab054f3ebffb2dfe4fbda417":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9af40339b6c54d7b809bf74761a1324c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e12175b4a7984be79246200a0c11f11c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47c8703dc38f43d196ae2ceb2b6be302":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7e7d4090aa24751b4b5d8b42e6f5752","IPY_MODEL_79b37f8650c947758aa25e49eaff39a5","IPY_MODEL_60f8338737474783ba6c7843b81e5fcb"],"layout":"IPY_MODEL_9416f5f77d724468a13418667143804d"}},"e7e7d4090aa24751b4b5d8b42e6f5752":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2db08c4a3f534363a99df57970047521","placeholder":"​","style":"IPY_MODEL_e2cb66d7d79545fc845126636cf9ff38","value":"thermal_cyclegan.pth: 100%"}},"79b37f8650c947758aa25e49eaff39a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f51b5957cb634eda9dfeb40bf4149a47","max":45519538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef5df3df5ab6471fa63be88e8dc33a71","value":45519538}},"60f8338737474783ba6c7843b81e5fcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9e735d303de437ca535f3734dc91a14","placeholder":"​","style":"IPY_MODEL_bb8721e8a63f421cbd154086cf902ff5","value":" 45.5M/45.5M [00:00&lt;00:00, 233MB/s]"}},"9416f5f77d724468a13418667143804d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db08c4a3f534363a99df57970047521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2cb66d7d79545fc845126636cf9ff38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f51b5957cb634eda9dfeb40bf4149a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5df3df5ab6471fa63be88e8dc33a71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9e735d303de437ca535f3734dc91a14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb8721e8a63f421cbd154086cf902ff5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"a2KnP6KGyvYf"}},{"cell_type":"code","source":["!git clone https://github.com/scksh/Thermal-CycleGAN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-xkf6NWyld0","executionInfo":{"status":"ok","timestamp":1753506607664,"user_tz":-540,"elapsed":24782,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"1bc562d4-eccb-4249-83ae-089f55c2b5d8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Thermal-CycleGAN'...\n","remote: Enumerating objects: 2323, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 2323 (delta 16), reused 28 (delta 9), pack-reused 2287 (from 1)\u001b[K\n","Receiving objects: 100% (2323/2323), 314.61 MiB | 15.67 MiB/s, done.\n","Resolving deltas: 100% (59/59), done.\n","Updating files: 100% (616/616), done.\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('Thermal-CycleGAN')"],"metadata":{"id":"gciMr7p6ylnA","executionInfo":{"status":"ok","timestamp":1753506607667,"user_tz":-540,"elapsed":2,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"921_z6Qkylvt","executionInfo":{"status":"ok","timestamp":1753506687553,"user_tz":-540,"elapsed":79884,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"c442e657-f474-470c-bc3b-82c87fc210dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n","Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n","  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.21.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.33.4)\n","Collecting pyngrok (from -r requirements.txt (line 7))\n","  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n","Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.11.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.33.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 6)) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 6)) (1.1.5)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n","Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n","Building wheels for collected packages: visdom\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=d32c806c1f7bba9d22c56ae949dd600b0a7f40fd818440c05b78ae89b9459f5d\n","  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n","Successfully built visdom\n","Installing collected packages: pyngrok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dominate, visdom, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed dominate-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyngrok-7.2.12 visdom-0.2.4\n"]}]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"f-pAUxL9Asci"}},{"cell_type":"code","source":["from huggingface_hub import hf_hub_download\n","import zipfile\n","\n","# Download dataset\n","zip_path = hf_hub_download(\n","    repo_id=\"SUMMERZETT/RGBSeg2IR\",\n","    filename=\"RGBSeg2IR.zip\",\n","    repo_type=\"dataset\"\n",")\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\"./datasets\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182,"referenced_widgets":["f0e16d7eb9c64a89a7336628c06404aa","ca7192e1109f465699738cdd49fe9d66","c19f8eb544e44fdab356ac99af9534a4","09a83dba494a412d97c9c8d55c37a733","0bd7414d885841f9997e96acb7bcddad","3b3865999e044ec9b48ac00150137087","5e80785c413d4fd38d29b80bba1f77d5","41ef578d5ff24a69ac7801fb2952930e","bf5bd69dab054f3ebffb2dfe4fbda417","9af40339b6c54d7b809bf74761a1324c","e12175b4a7984be79246200a0c11f11c"]},"id":"c_yjZhlPAvdw","executionInfo":{"status":"ok","timestamp":1753506702687,"user_tz":-540,"elapsed":6457,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"8c1cab85-c8eb-4d03-ef75-216e42e3a502"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["RGBSeg2IR.zip:   0%|          | 0.00/549M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e16d7eb9c64a89a7336628c06404aa"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Pre-trained model"],"metadata":{"id":"5HKRL4Y0BBIL"}},{"cell_type":"code","source":["from huggingface_hub import hf_hub_download\n","\n","# Download pretrained model\n","model_path = hf_hub_download(\n","    repo_id=\"SUMMERZETT/Thermal-CycleGAN\",\n","    filename=\"thermal_cyclegan.pth\",\n","    repo_type=\"model\",\n","    local_dir=\"./pretrained\",\n","    local_dir_use_symlinks=False\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126,"referenced_widgets":["47c8703dc38f43d196ae2ceb2b6be302","e7e7d4090aa24751b4b5d8b42e6f5752","79b37f8650c947758aa25e49eaff39a5","60f8338737474783ba6c7843b81e5fcb","9416f5f77d724468a13418667143804d","2db08c4a3f534363a99df57970047521","e2cb66d7d79545fc845126636cf9ff38","f51b5957cb634eda9dfeb40bf4149a47","ef5df3df5ab6471fa63be88e8dc33a71","b9e735d303de437ca535f3734dc91a14","bb8721e8a63f421cbd154086cf902ff5"]},"id":"lbToXMfHBAY2","executionInfo":{"status":"ok","timestamp":1753506703129,"user_tz":-540,"elapsed":441,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"da3bd464-83da-4706-f513-62a89db8f733"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n","For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["thermal_cyclegan.pth:   0%|          | 0.00/45.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c8703dc38f43d196ae2ceb2b6be302"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"iq31X3GmzI7z"}},{"cell_type":"code","source":["!python train.py --dataroot ./datasets/RGBSeg2IR --name RGBSeg2IR --model cycle_gan --direction AtoB --dataset_mode aligned --input_nc 4 --output_nc 1 --gpu_ids 0 --n_epochs 0 --n_epochs_decay 10 --lambda_identity 0 --lr_policy linear"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvvoIOCPyl4p","executionInfo":{"status":"ok","timestamp":1753507455485,"user_tz":-540,"elapsed":642067,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"98f22089-1e33-44c0-b97f-d131abf90027"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------- Options ---------------\n","               batch_size: 1                             \n","                    beta1: 0.5                           \n","          checkpoints_dir: ./checkpoints                 \n","           continue_train: False                         \n","                crop_size: 256                           \n","                 dataroot: ./datasets/RGBSeg2IR          \t[default: None]\n","             dataset_mode: aligned                       \t[default: unaligned]\n","                direction: AtoB                          \n","              display_env: main                          \n","             display_freq: 400                           \n","               display_id: 1                             \n","            display_ncols: 4                             \n","             display_port: 8097                          \n","           display_server: http://localhost              \n","          display_winsize: 256                           \n","                    epoch: latest                        \n","              epoch_count: 1                             \n","                 gan_mode: lsgan                         \n","                  gpu_ids: 0                             \n","                init_gain: 0.02                          \n","                init_type: normal                        \n","                 input_nc: 4                             \t[default: 3]\n","                  isTrain: True                          \t[default: None]\n","                 lambda_A: 10.0                          \n","                 lambda_B: 10.0                          \n","          lambda_identity: 0.0                           \t[default: 0.5]\n","                load_iter: 0                             \t[default: 0]\n","                load_size: 286                           \n","                       lr: 0.0002                        \n","           lr_decay_iters: 50                            \n","                lr_policy: linear                        \n","         max_dataset_size: inf                           \n","                    model: cycle_gan                     \n","                 n_epochs: 0                             \t[default: 100]\n","           n_epochs_decay: 10                            \t[default: 100]\n","               n_layers_D: 3                             \n","                     name: RGBSeg2IR                     \t[default: experiment_name]\n","                      ndf: 64                            \n","                     netD: basic                         \n","                     netG: resnet_9blocks                \n","                      ngf: 64                            \n","               no_dropout: True                          \n","                  no_flip: False                         \n","                  no_html: False                         \n","                     norm: instance                      \n","              num_threads: 4                             \n","                output_nc: 1                             \t[default: 3]\n","                    phase: train                         \n","                pool_size: 50                            \n","               preprocess: resize_and_crop               \n","               print_freq: 100                           \n","             save_by_iter: False                         \n","          save_epoch_freq: 5                             \n","         save_latest_freq: 5000                          \n","           serial_batches: False                         \n","                   suffix:                               \n","         update_html_freq: 1000                          \n","                use_wandb: False                         \n","                  verbose: False                         \n","       wandb_project_name: CycleGAN-and-pix2pix          \n","----------------- End -------------------\n","dataset [AlignedDataset] was created\n","The number of training images = 865\n","initialize network with normal\n","initialize network with normal\n","initialize network with normal\n","initialize network with normal\n","model [CycleGANModel] was created\n","---------- Networks initialized -------------\n","[Network G_A] Total number of parameters : 11.375 M\n","[Network G_B] Total number of parameters : 11.375 M\n","[Network D_A] Total number of parameters : 2.763 M\n","[Network D_B] Total number of parameters : 2.766 M\n","-----------------------------------------------\n","Setting up a new session...\n","create web directory ./checkpoints/RGBSeg2IR/web...\n","/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n","learning rate 0.0001818 -> 0.0001636\n","(epoch: 1, iters: 100, time: 0.069, data: 0.145) D_A: 0.281 G_A: 0.403 cycle_A: 3.695 idt_A: 0.000 D_B: 0.283 G_B: 0.430 cycle_B: 1.719 idt_B: 0.000 \n","(epoch: 1, iters: 200, time: 0.072, data: 0.001) D_A: 0.222 G_A: 0.275 cycle_A: 1.471 idt_A: 0.000 D_B: 0.125 G_B: 0.443 cycle_B: 1.539 idt_B: 0.000 \n","(epoch: 1, iters: 300, time: 0.069, data: 0.001) D_A: 0.248 G_A: 0.724 cycle_A: 1.799 idt_A: 0.000 D_B: 0.219 G_B: 0.335 cycle_B: 1.259 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 1, iters: 400, time: 0.367, data: 0.001) D_A: 0.173 G_A: 0.590 cycle_A: 4.834 idt_A: 0.000 D_B: 0.255 G_B: 0.314 cycle_B: 2.630 idt_B: 0.000 \n","(epoch: 1, iters: 500, time: 0.068, data: 0.001) D_A: 0.376 G_A: 0.503 cycle_A: 2.283 idt_A: 0.000 D_B: 0.300 G_B: 0.185 cycle_B: 0.896 idt_B: 0.000 \n","(epoch: 1, iters: 600, time: 0.070, data: 0.001) D_A: 0.078 G_A: 0.878 cycle_A: 2.378 idt_A: 0.000 D_B: 0.176 G_B: 0.608 cycle_B: 1.990 idt_B: 0.000 \n","(epoch: 1, iters: 700, time: 0.070, data: 0.001) D_A: 0.189 G_A: 0.543 cycle_A: 1.460 idt_A: 0.000 D_B: 0.233 G_B: 0.258 cycle_B: 1.435 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 1, iters: 800, time: 0.215, data: 0.001) D_A: 0.217 G_A: 0.230 cycle_A: 2.139 idt_A: 0.000 D_B: 0.274 G_B: 0.398 cycle_B: 1.672 idt_B: 0.000 \n","End of epoch 1 / 10 \t Time Taken: 63 sec\n","learning rate 0.0001636 -> 0.0001455\n","(epoch: 2, iters: 35, time: 0.071, data: 0.001) D_A: 0.134 G_A: 0.351 cycle_A: 1.963 idt_A: 0.000 D_B: 0.338 G_B: 0.433 cycle_B: 1.947 idt_B: 0.000 \n","(epoch: 2, iters: 135, time: 0.071, data: 0.001) D_A: 0.108 G_A: 0.500 cycle_A: 4.638 idt_A: 0.000 D_B: 0.195 G_B: 0.334 cycle_B: 1.074 idt_B: 0.000 \n","(epoch: 2, iters: 235, time: 0.069, data: 0.001) D_A: 0.172 G_A: 0.355 cycle_A: 2.395 idt_A: 0.000 D_B: 0.171 G_B: 0.387 cycle_B: 0.902 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 2, iters: 335, time: 0.349, data: 0.001) D_A: 0.193 G_A: 0.313 cycle_A: 2.187 idt_A: 0.000 D_B: 0.257 G_B: 0.318 cycle_B: 1.513 idt_B: 0.000 \n","(epoch: 2, iters: 435, time: 0.071, data: 0.001) D_A: 0.156 G_A: 0.300 cycle_A: 1.182 idt_A: 0.000 D_B: 0.297 G_B: 0.396 cycle_B: 0.862 idt_B: 0.000 \n","(epoch: 2, iters: 535, time: 0.068, data: 0.001) D_A: 0.143 G_A: 0.593 cycle_A: 2.261 idt_A: 0.000 D_B: 0.193 G_B: 0.439 cycle_B: 0.916 idt_B: 0.000 \n","(epoch: 2, iters: 635, time: 0.069, data: 0.001) D_A: 0.406 G_A: 0.202 cycle_A: 1.774 idt_A: 0.000 D_B: 0.153 G_B: 0.506 cycle_B: 1.584 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 2, iters: 735, time: 0.212, data: 0.001) D_A: 0.216 G_A: 0.447 cycle_A: 1.317 idt_A: 0.000 D_B: 0.267 G_B: 0.296 cycle_B: 1.091 idt_B: 0.000 \n","(epoch: 2, iters: 835, time: 0.068, data: 0.001) D_A: 0.103 G_A: 0.544 cycle_A: 2.235 idt_A: 0.000 D_B: 0.536 G_B: 0.807 cycle_B: 0.912 idt_B: 0.000 \n","End of epoch 2 / 10 \t Time Taken: 62 sec\n","learning rate 0.0001455 -> 0.0001273\n","(epoch: 3, iters: 70, time: 0.069, data: 0.001) D_A: 0.252 G_A: 0.268 cycle_A: 1.691 idt_A: 0.000 D_B: 0.279 G_B: 0.295 cycle_B: 2.464 idt_B: 0.000 \n","(epoch: 3, iters: 170, time: 0.069, data: 0.001) D_A: 0.155 G_A: 0.335 cycle_A: 3.190 idt_A: 0.000 D_B: 0.148 G_B: 0.486 cycle_B: 1.168 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 3, iters: 270, time: 0.341, data: 0.001) D_A: 0.086 G_A: 0.659 cycle_A: 2.415 idt_A: 0.000 D_B: 0.152 G_B: 0.486 cycle_B: 0.892 idt_B: 0.000 \n","(epoch: 3, iters: 370, time: 0.070, data: 0.001) D_A: 0.172 G_A: 0.401 cycle_A: 1.609 idt_A: 0.000 D_B: 0.263 G_B: 0.942 cycle_B: 1.199 idt_B: 0.000 \n","(epoch: 3, iters: 470, time: 0.070, data: 0.001) D_A: 0.076 G_A: 0.264 cycle_A: 3.428 idt_A: 0.000 D_B: 0.286 G_B: 0.257 cycle_B: 1.271 idt_B: 0.000 \n","(epoch: 3, iters: 570, time: 0.070, data: 0.001) D_A: 0.069 G_A: 0.549 cycle_A: 3.571 idt_A: 0.000 D_B: 0.197 G_B: 0.749 cycle_B: 1.302 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 3, iters: 670, time: 0.216, data: 0.001) D_A: 0.385 G_A: 0.092 cycle_A: 1.621 idt_A: 0.000 D_B: 0.181 G_B: 0.251 cycle_B: 1.724 idt_B: 0.000 \n","(epoch: 3, iters: 770, time: 0.069, data: 0.002) D_A: 0.264 G_A: 0.770 cycle_A: 2.186 idt_A: 0.000 D_B: 0.133 G_B: 0.093 cycle_B: 1.685 idt_B: 0.000 \n","End of epoch 3 / 10 \t Time Taken: 62 sec\n","learning rate 0.0001273 -> 0.0001091\n","(epoch: 4, iters: 5, time: 0.074, data: 0.001) D_A: 0.097 G_A: 0.263 cycle_A: 1.738 idt_A: 0.000 D_B: 0.231 G_B: 0.620 cycle_B: 1.269 idt_B: 0.000 \n","(epoch: 4, iters: 105, time: 0.069, data: 0.000) D_A: 0.122 G_A: 0.447 cycle_A: 2.032 idt_A: 0.000 D_B: 0.199 G_B: 0.373 cycle_B: 1.163 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 4, iters: 205, time: 0.357, data: 0.001) D_A: 0.081 G_A: 0.395 cycle_A: 1.913 idt_A: 0.000 D_B: 0.282 G_B: 0.654 cycle_B: 1.320 idt_B: 0.000 \n","(epoch: 4, iters: 305, time: 0.069, data: 0.001) D_A: 0.187 G_A: 0.401 cycle_A: 1.233 idt_A: 0.000 D_B: 0.072 G_B: 0.456 cycle_B: 1.802 idt_B: 0.000 \n","(epoch: 4, iters: 405, time: 0.072, data: 0.001) D_A: 0.110 G_A: 1.132 cycle_A: 1.589 idt_A: 0.000 D_B: 0.105 G_B: 0.635 cycle_B: 0.687 idt_B: 0.000 \n","(epoch: 4, iters: 505, time: 0.070, data: 0.001) D_A: 0.075 G_A: 0.517 cycle_A: 1.419 idt_A: 0.000 D_B: 0.101 G_B: 0.282 cycle_B: 1.106 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 4, iters: 605, time: 0.214, data: 0.001) D_A: 0.136 G_A: 0.385 cycle_A: 1.928 idt_A: 0.000 D_B: 0.169 G_B: 0.504 cycle_B: 1.108 idt_B: 0.000 \n","(epoch: 4, iters: 705, time: 0.071, data: 0.001) D_A: 0.182 G_A: 0.743 cycle_A: 1.584 idt_A: 0.000 D_B: 0.198 G_B: 0.500 cycle_B: 1.046 idt_B: 0.000 \n","(epoch: 4, iters: 805, time: 0.071, data: 0.001) D_A: 0.140 G_A: 0.361 cycle_A: 1.652 idt_A: 0.000 D_B: 0.229 G_B: 0.384 cycle_B: 0.952 idt_B: 0.000 \n","End of epoch 4 / 10 \t Time Taken: 62 sec\n","learning rate 0.0001091 -> 0.0000909\n","(epoch: 5, iters: 40, time: 0.069, data: 0.001) D_A: 0.133 G_A: 0.272 cycle_A: 1.459 idt_A: 0.000 D_B: 0.159 G_B: 0.295 cycle_B: 1.148 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 5, iters: 140, time: 0.357, data: 0.001) D_A: 0.064 G_A: 0.407 cycle_A: 2.035 idt_A: 0.000 D_B: 0.187 G_B: 0.868 cycle_B: 5.533 idt_B: 0.000 \n","(epoch: 5, iters: 240, time: 0.071, data: 0.001) D_A: 0.228 G_A: 0.288 cycle_A: 2.054 idt_A: 0.000 D_B: 0.075 G_B: 0.583 cycle_B: 1.014 idt_B: 0.000 \n","(epoch: 5, iters: 340, time: 0.071, data: 0.001) D_A: 0.056 G_A: 1.074 cycle_A: 1.622 idt_A: 0.000 D_B: 0.159 G_B: 0.326 cycle_B: 0.939 idt_B: 0.000 \n","(epoch: 5, iters: 440, time: 0.070, data: 0.001) D_A: 0.165 G_A: 0.196 cycle_A: 1.356 idt_A: 0.000 D_B: 0.152 G_B: 0.309 cycle_B: 1.779 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 5, iters: 540, time: 0.360, data: 0.001) D_A: 0.206 G_A: 0.726 cycle_A: 1.460 idt_A: 0.000 D_B: 0.111 G_B: 0.380 cycle_B: 0.945 idt_B: 0.000 \n","(epoch: 5, iters: 640, time: 0.071, data: 0.001) D_A: 0.153 G_A: 0.384 cycle_A: 1.578 idt_A: 0.000 D_B: 0.097 G_B: 0.086 cycle_B: 2.354 idt_B: 0.000 \n","(epoch: 5, iters: 740, time: 0.069, data: 0.001) D_A: 0.170 G_A: 0.561 cycle_A: 1.273 idt_A: 0.000 D_B: 0.250 G_B: 0.235 cycle_B: 1.414 idt_B: 0.000 \n","(epoch: 5, iters: 840, time: 0.071, data: 0.001) D_A: 0.119 G_A: 0.274 cycle_A: 1.886 idt_A: 0.000 D_B: 0.246 G_B: 0.303 cycle_B: 2.385 idt_B: 0.000 \n","saving the model at the end of epoch 5, iters 4325\n","End of epoch 5 / 10 \t Time Taken: 63 sec\n","learning rate 0.0000909 -> 0.0000727\n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 6, iters: 75, time: 0.373, data: 0.001) D_A: 0.188 G_A: 0.197 cycle_A: 1.338 idt_A: 0.000 D_B: 0.388 G_B: 0.059 cycle_B: 1.223 idt_B: 0.000 \n","(epoch: 6, iters: 175, time: 0.069, data: 0.001) D_A: 0.158 G_A: 0.527 cycle_A: 2.211 idt_A: 0.000 D_B: 0.146 G_B: 0.107 cycle_B: 1.263 idt_B: 0.000 \n","(epoch: 6, iters: 275, time: 0.069, data: 0.001) D_A: 0.160 G_A: 0.483 cycle_A: 2.110 idt_A: 0.000 D_B: 0.147 G_B: 0.521 cycle_B: 0.868 idt_B: 0.000 \n","(epoch: 6, iters: 375, time: 0.071, data: 0.001) D_A: 0.258 G_A: 0.174 cycle_A: 1.314 idt_A: 0.000 D_B: 0.208 G_B: 0.301 cycle_B: 0.639 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 6, iters: 475, time: 0.213, data: 0.001) D_A: 0.256 G_A: 0.221 cycle_A: 1.090 idt_A: 0.000 D_B: 0.096 G_B: 0.300 cycle_B: 1.090 idt_B: 0.000 \n","(epoch: 6, iters: 575, time: 0.073, data: 0.001) D_A: 0.440 G_A: 0.345 cycle_A: 1.617 idt_A: 0.000 D_B: 0.072 G_B: 0.214 cycle_B: 1.259 idt_B: 0.000 \n","(epoch: 6, iters: 675, time: 0.070, data: 0.001) D_A: 0.094 G_A: 0.325 cycle_A: 1.475 idt_A: 0.000 D_B: 0.101 G_B: 0.624 cycle_B: 0.791 idt_B: 0.000 \n","saving the latest model (epoch 6, total_iters 5000)\n","(epoch: 6, iters: 775, time: 0.069, data: 0.002) D_A: 0.220 G_A: 0.226 cycle_A: 1.278 idt_A: 0.000 D_B: 0.312 G_B: 0.448 cycle_B: 1.054 idt_B: 0.000 \n","End of epoch 6 / 10 \t Time Taken: 62 sec\n","learning rate 0.0000727 -> 0.0000545\n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 7, iters: 10, time: 0.387, data: 0.001) D_A: 0.068 G_A: 0.308 cycle_A: 2.434 idt_A: 0.000 D_B: 0.071 G_B: 0.266 cycle_B: 0.899 idt_B: 0.000 \n","(epoch: 7, iters: 110, time: 0.069, data: 0.001) D_A: 0.133 G_A: 0.317 cycle_A: 1.954 idt_A: 0.000 D_B: 0.122 G_B: 0.274 cycle_B: 0.593 idt_B: 0.000 \n","(epoch: 7, iters: 210, time: 0.071, data: 0.001) D_A: 0.116 G_A: 0.493 cycle_A: 1.891 idt_A: 0.000 D_B: 0.128 G_B: 0.267 cycle_B: 0.996 idt_B: 0.000 \n","(epoch: 7, iters: 310, time: 0.070, data: 0.001) D_A: 0.091 G_A: 0.292 cycle_A: 1.068 idt_A: 0.000 D_B: 0.238 G_B: 0.657 cycle_B: 0.916 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 7, iters: 410, time: 0.215, data: 0.001) D_A: 0.197 G_A: 0.139 cycle_A: 1.480 idt_A: 0.000 D_B: 0.116 G_B: 0.385 cycle_B: 0.717 idt_B: 0.000 \n","(epoch: 7, iters: 510, time: 0.070, data: 0.001) D_A: 0.137 G_A: 0.509 cycle_A: 1.424 idt_A: 0.000 D_B: 0.229 G_B: 0.308 cycle_B: 0.821 idt_B: 0.000 \n","(epoch: 7, iters: 610, time: 0.069, data: 0.001) D_A: 0.073 G_A: 0.326 cycle_A: 1.240 idt_A: 0.000 D_B: 0.152 G_B: 0.116 cycle_B: 1.421 idt_B: 0.000 \n","(epoch: 7, iters: 710, time: 0.069, data: 0.001) D_A: 0.064 G_A: 0.519 cycle_A: 2.918 idt_A: 0.000 D_B: 0.096 G_B: 0.398 cycle_B: 0.556 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 7, iters: 810, time: 0.354, data: 0.001) D_A: 0.169 G_A: 0.482 cycle_A: 2.310 idt_A: 0.000 D_B: 0.059 G_B: 0.354 cycle_B: 0.975 idt_B: 0.000 \n","End of epoch 7 / 10 \t Time Taken: 63 sec\n","learning rate 0.0000545 -> 0.0000364\n","(epoch: 8, iters: 45, time: 0.071, data: 0.001) D_A: 0.096 G_A: 0.503 cycle_A: 1.376 idt_A: 0.000 D_B: 0.121 G_B: 0.439 cycle_B: 0.910 idt_B: 0.000 \n","(epoch: 8, iters: 145, time: 0.072, data: 0.001) D_A: 0.244 G_A: 0.280 cycle_A: 2.198 idt_A: 0.000 D_B: 0.245 G_B: 0.360 cycle_B: 0.689 idt_B: 0.000 \n","(epoch: 8, iters: 245, time: 0.069, data: 0.001) D_A: 0.071 G_A: 0.461 cycle_A: 1.493 idt_A: 0.000 D_B: 0.026 G_B: 0.627 cycle_B: 0.841 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 8, iters: 345, time: 0.364, data: 0.001) D_A: 0.192 G_A: 0.304 cycle_A: 1.660 idt_A: 0.000 D_B: 0.208 G_B: 0.261 cycle_B: 0.577 idt_B: 0.000 \n","(epoch: 8, iters: 445, time: 0.071, data: 0.001) D_A: 0.161 G_A: 0.521 cycle_A: 1.446 idt_A: 0.000 D_B: 0.092 G_B: 0.340 cycle_B: 1.768 idt_B: 0.000 \n","(epoch: 8, iters: 545, time: 0.071, data: 0.001) D_A: 0.152 G_A: 0.302 cycle_A: 1.731 idt_A: 0.000 D_B: 0.262 G_B: 0.361 cycle_B: 0.863 idt_B: 0.000 \n","(epoch: 8, iters: 645, time: 0.072, data: 0.001) D_A: 0.130 G_A: 0.762 cycle_A: 1.846 idt_A: 0.000 D_B: 0.047 G_B: 0.355 cycle_B: 0.647 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 8, iters: 745, time: 0.217, data: 0.001) D_A: 0.351 G_A: 0.130 cycle_A: 1.392 idt_A: 0.000 D_B: 0.191 G_B: 0.754 cycle_B: 0.718 idt_B: 0.000 \n","(epoch: 8, iters: 845, time: 0.071, data: 0.001) D_A: 0.053 G_A: 0.471 cycle_A: 1.974 idt_A: 0.000 D_B: 0.168 G_B: 0.226 cycle_B: 0.989 idt_B: 0.000 \n","End of epoch 8 / 10 \t Time Taken: 62 sec\n","learning rate 0.0000364 -> 0.0000182\n","(epoch: 9, iters: 80, time: 0.071, data: 0.001) D_A: 0.219 G_A: 0.310 cycle_A: 1.760 idt_A: 0.000 D_B: 0.154 G_B: 0.495 cycle_B: 0.536 idt_B: 0.000 \n","(epoch: 9, iters: 180, time: 0.073, data: 0.001) D_A: 0.274 G_A: 0.183 cycle_A: 1.274 idt_A: 0.000 D_B: 0.199 G_B: 0.342 cycle_B: 0.659 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 9, iters: 280, time: 0.388, data: 0.001) D_A: 0.146 G_A: 0.282 cycle_A: 1.036 idt_A: 0.000 D_B: 0.142 G_B: 0.488 cycle_B: 0.777 idt_B: 0.000 \n","(epoch: 9, iters: 380, time: 0.070, data: 0.001) D_A: 0.119 G_A: 0.712 cycle_A: 0.997 idt_A: 0.000 D_B: 0.052 G_B: 0.211 cycle_B: 0.693 idt_B: 0.000 \n","(epoch: 9, iters: 480, time: 0.071, data: 0.001) D_A: 0.081 G_A: 0.498 cycle_A: 0.925 idt_A: 0.000 D_B: 0.146 G_B: 0.265 cycle_B: 0.479 idt_B: 0.000 \n","(epoch: 9, iters: 580, time: 0.071, data: 0.001) D_A: 0.124 G_A: 0.272 cycle_A: 1.344 idt_A: 0.000 D_B: 0.086 G_B: 0.272 cycle_B: 1.243 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 9, iters: 680, time: 0.218, data: 0.001) D_A: 0.160 G_A: 0.414 cycle_A: 2.367 idt_A: 0.000 D_B: 0.033 G_B: 0.375 cycle_B: 0.900 idt_B: 0.000 \n","(epoch: 9, iters: 780, time: 0.080, data: 0.002) D_A: 0.092 G_A: 0.146 cycle_A: 1.065 idt_A: 0.000 D_B: 0.109 G_B: 0.512 cycle_B: 1.080 idt_B: 0.000 \n","End of epoch 9 / 10 \t Time Taken: 63 sec\n","learning rate 0.0000182 -> 0.0000000\n","(epoch: 10, iters: 15, time: 0.074, data: 0.001) D_A: 0.111 G_A: 0.421 cycle_A: 1.364 idt_A: 0.000 D_B: 0.199 G_B: 0.400 cycle_B: 0.673 idt_B: 0.000 \n","(epoch: 10, iters: 115, time: 0.070, data: 0.001) D_A: 0.338 G_A: 0.318 cycle_A: 1.244 idt_A: 0.000 D_B: 0.324 G_B: 0.285 cycle_B: 0.645 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 10, iters: 215, time: 0.389, data: 0.001) D_A: 0.167 G_A: 0.249 cycle_A: 1.026 idt_A: 0.000 D_B: 0.203 G_B: 0.400 cycle_B: 0.598 idt_B: 0.000 \n","(epoch: 10, iters: 315, time: 0.071, data: 0.002) D_A: 0.302 G_A: 0.250 cycle_A: 1.161 idt_A: 0.000 D_B: 0.158 G_B: 0.463 cycle_B: 0.910 idt_B: 0.000 \n","(epoch: 10, iters: 415, time: 0.077, data: 0.001) D_A: 0.202 G_A: 0.465 cycle_A: 2.302 idt_A: 0.000 D_B: 0.182 G_B: 0.551 cycle_B: 0.506 idt_B: 0.000 \n","(epoch: 10, iters: 515, time: 0.079, data: 0.001) D_A: 0.055 G_A: 0.609 cycle_A: 1.324 idt_A: 0.000 D_B: 0.238 G_B: 0.537 cycle_B: 0.736 idt_B: 0.000 \n","====== current visuals ======\n","real_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","fake_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","rec_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","real_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","fake_A: shape=torch.Size([1, 4, 256, 256]), dtype=torch.float32\n","rec_B: shape=torch.Size([1, 1, 256, 256]), dtype=torch.float32\n","=============================\n","(epoch: 10, iters: 615, time: 0.215, data: 0.001) D_A: 0.040 G_A: 0.401 cycle_A: 1.138 idt_A: 0.000 D_B: 0.160 G_B: 0.618 cycle_B: 0.781 idt_B: 0.000 \n","(epoch: 10, iters: 715, time: 0.069, data: 0.002) D_A: 0.109 G_A: 0.459 cycle_A: 1.150 idt_A: 0.000 D_B: 0.143 G_B: 0.331 cycle_B: 0.726 idt_B: 0.000 \n","(epoch: 10, iters: 815, time: 0.071, data: 0.001) D_A: 0.091 G_A: 0.539 cycle_A: 1.184 idt_A: 0.000 D_B: 0.097 G_B: 0.631 cycle_B: 0.929 idt_B: 0.000 \n","saving the model at the end of epoch 10, iters 8650\n","End of epoch 10 / 10 \t Time Taken: 64 sec\n"]}]},{"cell_type":"markdown","source":["# Generate"],"metadata":{"id":"v3w921IyHHMJ"}},{"cell_type":"code","source":["!python generate.py --rgb_dir ./datasets/RGBSeg2IR/testA --seg_dir ./datasets/RGBSeg2IR/testSegA --model_path ./pretrained/thermal_cyclegan.pth --output_dir ./results/generated_IR --gpu_ids 0"],"metadata":{"id":"XnFqD4v3ymXZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753507606189,"user_tz":-540,"elapsed":40861,"user":{"displayName":"seung hwan Kim","userId":"11286953022294034627"}},"outputId":"c9bce0d1-07ce-4281-99df-a6e66126de5a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["initialize network with normal\n","Model loaded from: ./pretrained/thermal_cyclegan.pth\n","Generating IR images: 100% 2358/2358 [00:37<00:00, 63.42it/s]\n","All images saved to: ./results/generated_IR\n"]}]}]}