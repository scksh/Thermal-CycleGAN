import torch
from PIL import Image
import torchvision.transforms as transforms
from models import networks
import os
import sys

# ê²½ë¡œ ì„¤ì •
base_dir = r"/home/ricky"
rgb_dir = os.path.join(base_dir, "images")
seg_dir = os.path.join(base_dir, "output_masks")
out_dir = os.path.join(base_dir, "thermal")
model_path = os.path.join(base_dir, "latest_net_G_A.pth")

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(out_dir, exist_ok=True)

# ëª¨ë¸ ì •ì˜ ë° ë¶ˆëŸ¬ì˜¤ê¸° (ì…ë ¥ 4ì±„ë„, ì¶œë ¥ 1ì±„ë„)
netG = networks.define_G(
    input_nc=4, output_nc=1, ngf=64, netG='resnet_9blocks',
    norm='instance', use_dropout=False, init_type='normal',
    init_gain=0.02, gpu_ids=[]
)
netG.load_state_dict(torch.load(model_path, map_location='cpu'))  # GPU ì‚¬ìš©ì‹œ map_location='cuda:0'
netG.eval()

# ì „ì²˜ë¦¬ ì •ì˜
transform_rgb = transforms.Compose([
    transforms.Resize((1280, 720)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

transform_seg = transforms.Compose([
    transforms.Resize((1280, 720)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# ğŸ” ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
for filename in os.listdir(rgb_dir):
    if not filename.lower().endswith((".jpg", ".png", ".jpeg")):
        continue

    rgb_path = os.path.join(rgb_dir, filename)
    seg_path = os.path.join(seg_dir, filename.replace(".jpg", "_combined_mask.png"))  # ë§ˆìŠ¤í¬ëŠ” _mask ë¶™ìŒ
    output_path = os.path.join(out_dir, filename.replace(".jpg", "_thermal.png"))

    if not os.path.exists(seg_path):
        print(f"âŒ ë§ˆìŠ¤í¬ ì—†ìŒ: {seg_path}")
        continue

    try:
        rgb_img = Image.open(rgb_path).convert('RGB')
        seg_img = Image.open(seg_path).convert('L')
    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {filename}, ì—ëŸ¬: {e}")
        continue

    # ì „ì²˜ë¦¬
    rgb_tensor = transform_rgb(rgb_img)
    seg_tensor = transform_seg(seg_img)

    # [1, 4, 256, 256]
    input_tensor = torch.cat([rgb_tensor, seg_tensor], dim=0).unsqueeze(0)

    # ì¶”ë¡ 
    with torch.no_grad():
        output_tensor = netG(input_tensor)

    # í›„ì²˜ë¦¬ ë° ì €ì¥
    output_image = output_tensor.squeeze().detach().cpu()
    output_image = (output_image + 1) / 2.0  # [-1, 1] â†’ [0, 1]
    output_image = transforms.ToPILImage()(output_image)
    output_image.save(output_path)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")

print("ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ.")

