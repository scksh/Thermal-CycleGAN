import os
import cv2
import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
import torchvision.transforms as transforms
from models import networks

# === ì„¤ì • ===
PAD = 30
SAVE_FORMAT = "jpg"  # ë˜ëŠ” "png"
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

# === ê²½ë¡œ ì„¤ì • ===
base_dir = "/home/ricky/Data/drone_video/445_exp"
img_dir = os.path.join(base_dir, "images")
label_dir = os.path.join(base_dir, "labels")
mask_dir = os.path.join(base_dir, "masks")  # ì›ë³¸í¬ê¸° ë§ˆìŠ¤í¬ ìœ„ì¹˜
output_dir = os.path.join(base_dir, "output")
os.makedirs(output_dir, exist_ok=True)

# === ëª¨ë¸ ë¡œë“œ ===
netG = networks.define_G(
    input_nc=4, output_nc=1, ngf=64, netG='resnet_9blocks',
    norm='instance', use_dropout=False, init_type='normal',
    init_gain=0.02, gpu_ids=[]
)
model_path = "/home/ricky/Data/checkpoints/person/latest_net_G_A.pth"
netG.load_state_dict(torch.load(model_path, map_location=device))
netG.to(device)
netG.eval()

normalize_rgb = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
normalize_seg = transforms.Normalize((0.5,), (0.5,))

img_files = sorted([f for f in os.listdir(img_dir) if f.endswith((".jpg", ".png"))])

for img_file in tqdm(img_files, desc="ì—´í™”ìƒ ìƒì„± ì¤‘"):
    name = os.path.splitext(img_file)[0]
    img_path = os.path.join(img_dir, img_file)
    label_path = os.path.join(label_dir, name + ".txt")
    mask_path = os.path.join(mask_dir, name + ".png")  # ë§ˆìŠ¤í¬ëŠ” ì›ë³¸ í¬ê¸° ê¸°ì¤€
    output_path = os.path.join(output_dir, f"{name}.{SAVE_FORMAT}")
    alt_ext = "png" if SAVE_FORMAT == "jpg" else "jpg"
    output_path_alt = os.path.join(output_dir, f"{name}.{alt_ext}")

    # ê²°ê³¼ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
    if os.path.exists(output_path) or os.path.exists(output_path_alt):
        print(f"â© ìŠ¤í‚µ: {name} (ì´ë¯¸ ì¡´ì¬)")
        continue

    orig_img = cv2.imread(img_path)
    if orig_img is None:
        print(f"[ê²½ê³ ] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
        continue

    h, w = orig_img.shape[:2]

    # === ê°ì²´ ìœ ë¬´ íŒë‹¨
    has_object = False
    if os.path.exists(label_path):
        with open(label_path) as f:
            has_object = len(f.read().strip()) > 0

    if not has_object:
        # ê°ì²´ ì—†ìŒ: íŒ¨ë”© ì¶”ê°€ + ê°€ì§œ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
        padded_img = cv2.copyMakeBorder(orig_img, 0, 0, PAD, 0, cv2.BORDER_REFLECT)
        mask = np.zeros((h, w + PAD), dtype=np.uint8)
        cv2.rectangle(mask, (5, h // 2 - 15), (25, h // 2 + 15), color=255, thickness=-1)
        crop_output = True
    else:
        # ğŸ‘‰ ê°ì²´ ìˆìŒ: ì›ë³¸ ì´ë¯¸ì§€ + ì›ë³¸ í¬ê¸° ë§ˆìŠ¤í¬ ì‚¬ìš©
        padded_img = orig_img
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            print(f"[ê²½ê³ ] ë§ˆìŠ¤í¬ ë¡œë“œ ì‹¤íŒ¨ â†’ ìŠ¤í‚µ: {mask_path}")
            continue
        crop_output = False

    # === ì—´í™”ìƒ ìƒì„± ===
    try:
        rgb_img = Image.fromarray(cv2.cvtColor(padded_img, cv2.COLOR_BGR2RGB)).convert('RGB')
        seg_img = Image.fromarray(mask).convert('L')

        rgb_tensor = normalize_rgb(transforms.ToTensor()(rgb_img))
        seg_tensor = normalize_seg(transforms.ToTensor()(seg_img))
        input_tensor = torch.cat([rgb_tensor, seg_tensor], dim=0).unsqueeze(0).to(device)

        with torch.no_grad():
            output_tensor = netG(input_tensor)

        output_image = output_tensor.squeeze().cpu()
        output_image = (output_image + 1) / 2.0
        output_np = (output_image.numpy() * 255).astype(np.uint8)

        if crop_output:
            output_np = output_np[:, PAD:PAD + w]  # ì¢Œì¸¡ PAD ì˜ë¼ëƒ„
        output_np = np.clip(output_np, 0, 255)

        if SAVE_FORMAT == "jpg":
            cv2.imwrite(output_path, output_np, [cv2.IMWRITE_JPEG_QUALITY, 95])
        else:
            cv2.imwrite(output_path, output_np)

        print(f"ì €ì¥ ì™„ë£Œ: {output_path}")

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {img_file} | {e}")

print("ì—´í™”ìƒ ìƒì„± ì™„ë£Œ!")

output_dir = os.path.join(base_dir, "output")
os.makedirs(output_dir, exist_ok=True)

# === ëª¨ë¸ ë¡œë“œ ===
netG = networks.define_G(
    input_nc=4, output_nc=1, ngf=64, netG='resnet_9blocks',
    norm='instance', use_dropout=False, init_type='normal',
    init_gain=0.02, gpu_ids=[]
)
model_path = "/home/ricky/Data/checkpoints/person/latest_net_G_A.pth"
netG.load_state_dict(torch.load(model_path, map_location=device))
netG.to(device)
netG.eval()

normalize_rgb = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
normalize_seg = transforms.Normalize((0.5,), (0.5,))

img_files = sorted([f for f in os.listdir(img_dir) if f.endswith((".jpg", ".png"))])

for img_file in tqdm(img_files, desc="ì—´í™”ìƒ ìƒì„± ì¤‘"):
    name = os.path.splitext(img_file)[0]
    img_path = os.path.join(img_dir, img_file)
    label_path = os.path.join(label_dir, name + ".txt")
    mask_path = os.path.join(mask_dir, name + ".png")  # ë§ˆìŠ¤í¬ëŠ” ì›ë³¸ í¬ê¸° ê¸°ì¤€
    output_path = os.path.join(output_dir, f"{name}.{SAVE_FORMAT}")
    alt_ext = "png" if SAVE_FORMAT == "jpg" else "jpg"
    output_path_alt = os.path.join(output_dir, f"{name}.{alt_ext}")

    # ê²°ê³¼ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
    if os.path.exists(output_path) or os.path.exists(output_path_alt):
        print(f"â© ìŠ¤í‚µ: {name} (ì´ë¯¸ ì¡´ì¬)")
        continue

    orig_img = cv2.imread(img_path)
    if orig_img is None:
        print(f"[ê²½ê³ ] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
        continue

    h, w = orig_img.shape[:2]

    # === ê°ì²´ ìœ ë¬´ íŒë‹¨
    has_object = False
    if os.path.exists(label_path):
        with open(label_path) as f:
            has_object = len(f.read().strip()) > 0

    if not has_object:
        # ê°ì²´ ì—†ìŒ: íŒ¨ë”© ì¶”ê°€ + ê°€ì§œ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
        padded_img = cv2.copyMakeBorder(orig_img, 0, 0, PAD, 0, cv2.BORDER_REFLECT)
        mask = np.zeros((h, w + PAD), dtype=np.uint8)
        cv2.rectangle(mask, (5, h // 2 - 15), (25, h // 2 + 15), color=255, thickness=-1)
        crop_output = True
    else:
        # ê°ì²´ ìˆìŒ: ì›ë³¸ ì´ë¯¸ì§€ + ì›ë³¸ í¬ê¸° ë§ˆìŠ¤í¬ ì‚¬ìš©
        padded_img = orig_img
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            print(f"[ê²½ê³ ] ë§ˆìŠ¤í¬ ë¡œë“œ ì‹¤íŒ¨ â†’ ìŠ¤í‚µ: {mask_path}")
            continue
        crop_output = False

    # === ì—´í™”ìƒ ìƒì„± ===
    try:
        rgb_img = Image.fromarray(cv2.cvtColor(padded_img, cv2.COLOR_BGR2RGB)).convert('RGB')
        seg_img = Image.fromarray(mask).convert('L')

        rgb_tensor = normalize_rgb(transforms.ToTensor()(rgb_img))
        seg_tensor = normalize_seg(transforms.ToTensor()(seg_img))
        input_tensor = torch.cat([rgb_tensor, seg_tensor], dim=0).unsqueeze(0).to(device)

        with torch.no_grad():
            output_tensor = netG(input_tensor)

        output_image = output_tensor.squeeze().cpu()
        output_image = (output_image + 1) / 2.0
        output_np = (output_image.numpy() * 255).astype(np.uint8)

        if crop_output:
            output_np = output_np[:, PAD:PAD + w]  # ì¢Œì¸¡ PAD ì˜ë¼ëƒ„
        output_np = np.clip(output_np, 0, 255)

        if SAVE_FORMAT == "jpg":
            cv2.imwrite(output_path, output_np, [cv2.IMWRITE_JPEG_QUALITY, 95])
        else:
            cv2.imwrite(output_path, output_np)

        print(f"ì €ì¥ ì™„ë£Œ: {output_path}")

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {img_file} | {e}")

print("ì—´í™”ìƒ ìƒì„± ì™„ë£Œ!")
